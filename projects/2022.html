<!DOCTYPE html><html class="__variable_267f73 __variable_a17134" lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/34a9823ac715e2c2-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/4f05ba3a6752a328-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/88f55461e8246337-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/8f32c48a86b1398a-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/aa2fa0bf32820007-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/e0c8a07f5438bca2-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/d18faa20e57b8c8f.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/8084700d1b690744.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/a64b62f1bc63fa38.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/7e01d6c3b6734420.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/3051e00fa45cc288.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-8a83a2adec5ecfb1.js"/><script src="/_next/static/chunks/4bd1b696-d6b5e8540b372a60.js" async=""></script><script src="/_next/static/chunks/899-5230e61a129dbe4b.js" async=""></script><script src="/_next/static/chunks/main-app-d2b433dd5a7d6e56.js" async=""></script><script src="/_next/static/chunks/app/layout-cb2528e11420f193.js" async=""></script><script src="/_next/static/chunks/282-afc53b6356b91afc.js" async=""></script><script src="/_next/static/chunks/45-f916d720bcb3974c.js" async=""></script><script src="/_next/static/chunks/8-b4524a3a6a8ca38b.js" async=""></script><script src="/_next/static/chunks/app/projects/%5Bproject%5D/page-50d3f8ee355b2eaf.js" async=""></script><meta name="next-size-adjust" content=""/><title>Projects - Brainhack Western 2025</title><meta name="description" content="Projects pitched at Brainhack Western"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="250x250"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_4bc053"><div class="_1n606ht0"><nav class="_3dd9ih1 navbar navbar-expand-lg navbar-light sticky-top"><div class="container-fluid"><a class="navbar-brand" href="/"><img alt="Home" loading="lazy" width="58" height="40" decoding="async" data-nimg="1" style="color:transparent" srcSet="https://brainhack-western.imgix.net/_next/static/media/brainhack_logo.4ec5cb2d.png?auto=format&amp;fit=max&amp;w=64&amp;q=50 1x, https://brainhack-western.imgix.net/_next/static/media/brainhack_logo.4ec5cb2d.png?auto=format&amp;fit=max&amp;w=128&amp;q=50 2x" src="https://brainhack-western.imgix.net/_next/static/media/brainhack_logo.4ec5cb2d.png?auto=format&amp;fit=max&amp;w=128&amp;q=50"/></a><button aria-label="Toggle navigation" type="button" class="navbar-toggler collapsed"><span class="navbar-toggler-icon"></span></button><div class="navbar-collapse collapse" id="basic-navbar-nav"><div class="me-auto navbar-nav"><div class="nav-item"><a class="nav-link" href="/#about">About</a></div><div class="nav-item"><a class="nav-link" href="/#location">Location</a></div><div class="nav-item"><a class="nav-link" href="/projects/2023">Projects</a></div><div class="nav-item"><a class="nav-link" href="/FAQ">FAQ</a></div><div class="nav-item"><a class="nav-link" href="https://brainhack.org/code-of-conduct.html">Code of Conduct</a></div></div><span class="_3dd9ih2 "></span></div></div></nav><article class="_1p0a9t10 container-lg"><h1>Projects</h1><div class="_1k0mdyo0"><div class="_1k0mdyo1"><div class="container-lg"><div class="row"><p class="d-flex flex-column align-items-center justify-content-center col-lg-6">Project Submission for Brainhack Western <!-- -->2025<!-- --> will open soon!<br/>In the meantime, check out the project pitches from previous years.</p><div class="col-lg-6"><div class="align-self-lg-center"><div class="console "><span><span class="blue"># Coming soon</span><br/><span>Mar 19 - Mar 21</span></span></div></div></div></div></div></div></div><style data-emotion="css ou2fx3-container">.css-ou2fx3-container{position:relative;box-sizing:border-box;max-width:250px;margin-bottom:1em;}</style><div class="css-ou2fx3-container"><style data-emotion="css 7pg0cj-a11yText">.css-7pg0cj-a11yText{z-index:9999;border:0;clip:rect(1px, 1px, 1px, 1px);height:1px;width:1px;position:absolute;overflow:hidden;padding:0;white-space:nowrap;}</style><span id="react-select-3-live-region" class="css-7pg0cj-a11yText"></span><span aria-live="polite" aria-atomic="false" aria-relevant="additions text" role="log" class="css-7pg0cj-a11yText"></span><style data-emotion="css 12xzhlj-control">.css-12xzhlj-control{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:default;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;min-height:38px;outline:0!important;position:relative;-webkit-transition:all 100ms;transition:all 100ms;background-color:#0f0f0f;border-color:#0b0b0b;border-radius:0;border-style:solid;border-width:1px;box-sizing:border-box;}.css-12xzhlj-control:hover{border-color:#01ac3d;}</style><div class="css-12xzhlj-control"><style data-emotion="css hlgwow">.css-hlgwow{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:grid;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-overflow-scrolling:touch;position:relative;overflow:hidden;padding:2px 8px;box-sizing:border-box;}</style><div class="css-hlgwow"><style data-emotion="css irplos-singleValue">.css-irplos-singleValue{grid-area:1/1/2/3;max-width:100%;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;color:#f9f9f9;margin-left:2px;margin-right:2px;box-sizing:border-box;}</style><div class="css-irplos-singleValue">2022</div><style data-emotion="css 1hac4vs-dummyInput">.css-1hac4vs-dummyInput{background:0;border:0;caret-color:transparent;font-size:inherit;grid-area:1/1/2/3;outline:0;padding:0;width:1px;color:transparent;left:-100px;opacity:0;position:relative;-webkit-transform:scale(.01);-moz-transform:scale(.01);-ms-transform:scale(.01);transform:scale(.01);}</style><input id="react-select-3-input" tabindex="0" inputMode="none" aria-autocomplete="list" aria-expanded="false" aria-haspopup="true" role="combobox" aria-activedescendant="" aria-readonly="true" class="css-1hac4vs-dummyInput" value=""/></div><style data-emotion="css 1wy0on6">.css-1wy0on6{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;}</style><div class="css-1wy0on6"><style data-emotion="css 1hhdqpn-indicatorSeparator">.css-1hhdqpn-indicatorSeparator{-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;width:1px;background-color:#2f2f2f;margin-bottom:8px;margin-top:8px;box-sizing:border-box;}</style><span class="css-1hhdqpn-indicatorSeparator"></span><style data-emotion="css 1vqbq7m-indicatorContainer">.css-1vqbq7m-indicatorContainer{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-transition:color 150ms;transition:color 150ms;color:#2f2f2f;padding:8px;box-sizing:border-box;}.css-1vqbq7m-indicatorContainer:hover{color:#01ac3d;}</style><div class="css-1vqbq7m-indicatorContainer" aria-hidden="true"><style data-emotion="css 8mmkcg">.css-8mmkcg{display:inline-block;fill:currentColor;line-height:1;stroke:currentColor;stroke-width:0;}</style><svg height="20" width="20" viewBox="0 0 20 20" aria-hidden="true" focusable="false" class="css-8mmkcg"><path d="M4.516 7.548c0.436-0.446 1.043-0.481 1.576 0l3.908 3.747 3.908-3.747c0.533-0.481 1.141-0.446 1.574 0 0.436 0.445 0.408 1.197 0 1.615-0.406 0.418-4.695 4.502-4.695 4.502-0.217 0.223-0.502 0.335-0.787 0.335s-0.57-0.112-0.789-0.335c0 0-4.287-4.084-4.695-4.502s-0.436-1.17 0-1.615z"></path></svg></div></div></div></div><section id="Safer-Multimodal-Teleoperation-of-Simulated-Robots"><h3>Safer Multimodal Teleoperation of (Simulated) Robots</h3><div class="console "><span><p>Being confused, freezing, or panicking while trying hard to stop,
re-direct, or stabilize a drone (or any such robot/toy) in sudden
counter-intuitive poses or environmental conditions is likely a
relatable experience for all of us. The idea here is about enhancing the
expression of our intent while controlling a robot remotely ‚Äî either in
real life or on a computer screen (simulation) ‚Äî while not replacing the
primary instrument of control (modality) but instead by also integrating
our brain states (thought) in the control loop as measured, for example,
through EEG. Specifically, for the scope of the hackathon, this could
mean developing a brain-machine interface for automatically assisting
the operator in emergency cases with ‚Äúsmart‚Äù control command reflexes or
‚Äútakeovers‚Äù. Such an approach can be beneficial in high-risk cases such
as remote handling of materials in nuclear facilities or it can also aid
the supervision of autonomous control, say in the context of
self-driving cars, to ultimately increase safety.</p>
<p>For now, we could pick a particular type of simulated robot (industrial
arms, RC cars, drones, etc.) and focus on designing and implementing a
paradigm for characterizing intended motion and surprise during
undesired motion in both autonomous (with no user control but robot&#x27;s
self- and environmental influences) or semi-autonomous cases (including
user&#x27;s control commands), i.e., we can aim to measure intent and
surprise given the user&#x27;s control commands, the brain states, and robot
states during algorithmically curated cases of robot motion. This will
help us detect such situations and also infer desired reactions to
accordingly adjust control commands to achieve desired reactions during
emergencies and, more generally, to augment real-time active control to
match the desired motion. We can strive to keep the approach suitable
for generalizing well enough to robots of other types and/or
morphologies and to more unusual environments.</p><div><span class="green">Organizer: </span><br/><div class="d-flex"><span>¬†¬†-¬†</span><div>Pranshu Malik<!-- --> <!-- -->(<a href="https://github.com/pranshumalik14">@<!-- -->pranshumalik14</a>)</div><br/></div></div></span></div></section><section id="Brain3DVis-AR/MR-MRI-Visualizer"><h3>Brain3DVis: AR/MR MRI Visualizer</h3><div class="console "><span><p>Application that uses a web-based front end where users can submit brain
MRI volumes. The data is then processed on the application backend, a 3D
model is generated, and is then accessible in a AR/VR environment. We
are using the MERN stack for the web component and C#/Unity for the
AR/VR application. We would love to work with people who have experience
with MRI volumetric segmentation or are interested in VR/AR data
visualization. <span role="img" aria-label="slightly smiling face emoji">üôÇ</span></p><div><span class="green">Organizer: </span><br/><div class="d-flex"><span>¬†¬†-¬†</span><div>Liam Bilbie<!-- --> <!-- -->(<a href="https://github.com/LiamBilbie">@<!-- -->LiamBilbie</a>)</div><br/></div></div></span></div></section><section id="Functional-Atlas-Explorer"><h3>Functional Atlas Explorer</h3><div class="console "><span><p>&quot;What does the inferior frontal gyrus do?&quot; Googling this question
returns 93,400,000 results. A skim read of paper abstracts will give you
some ideas about its functions. But wouldn&#x27;t it be useful to have an
interactive map where you can explore these functions in the brain?
Imagine clicking on a brain region and getting a word cloud of functions
that this region is highly involved in. That&#x27;s what we will build!</p>
<p>We will create an interactive tool, useful for anyone wanting to explore
their own functional data or openly available functional datasets.
Together with our functional fusion toolbox (in-house &amp; soon to be
released), it lets you integrate information from many different openly
available datasets (Human Connectome Project, etc).</p>
<p>During the project you will be able to use our existing toolbox to
explore these large datasets - as well as your own data! In addition,
this interactive map will provide a side by side view of your desired
brain regions and their connections with other brain regions. Click on a
region and you get a map of its functional connectivity to all other
regions in the brain.</p>
<p>The tool will help synthesize findings across studies (think Neurosynth,
but directly based on fMRI data) and aid interpretation of results as
well as planning of future experiments.</p><div><span class="green">Organizers: </span><br/><div class="d-flex"><span>¬†¬†-¬†</span><div>Caroline Nettekoven<!-- --> <!-- -->(<a href="https://github.com/carobellum">@<!-- -->carobellum</a>)</div><br/></div><div class="d-flex"><span>¬†¬†-¬†</span><div>Ladan Shahshahani<!-- --> <!-- -->(<a href="https://github.com/lshahsha">@<!-- -->lshahsha</a>)</div><br/></div></div></span></div></section><section id="DWI-Fiducials"><h3>DWI Fiducials</h3><div class="console "><span><p>Diffusion-Weighted Imaging (DWI) is a variant of the standard MRI
sequence examining the diffusion rate of water molecules.  DWI or
Diffusion MRI has allowed for the improved study of white matter
pathways across both diseased and healthy patients.</p>
<p>The goal of the diffusion Fiducials or dFIDs project is to identify a
set of anatomical landmarks on a variety of Diffusion-Weighted MRI
images that are both salient and have functional significance.  This
will be an extension of the previous Anatomical Fiducials (AFIDs)
project that has localized a set of 32 clinically-relevant landmarks in
humans, macaques, and PD patients in multiple imaging acquisitions (see
<a href="https://doi.org/10.1002/hbm.24693">https://doi.org/10.1002/hbm.24693</a>).</p>
<p>We are looking for students, researchers, and clinicians to determine
potential fiducials across various acquisition types and models in DWI.
Those with experience in acquiring diffusion images or who have an
interest in neuroimaging or anatomy are welcome to join!</p><div><span class="green">Organizer: </span><br/><div class="d-flex"><span>¬†¬†-¬†</span><div>Arun Thurairajah</div><br/></div></div></span></div></section></article><footer class="_1d8l4x30"><div class="_1d1a9if0  container-lg"><div class="row"><div class="col-lg-6 d-flex flex-column justify-content-start align-items-start"><h3>Organizers</h3><p class="organizers">Ali Tafakkor, Peter Van Dyken, Ali Khan</p></div></div><h3 id="contact">Contact</h3><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><p class="_1d8l4x31">Copyright ¬© <!-- -->2025<!-- --> Brainhack Western</p></div></footer></div><script src="/_next/static/chunks/webpack-8a83a2adec5ecfb1.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[19687,[\"177\",\"static/chunks/app/layout-cb2528e11420f193.js\"],\"ScrollPositionProvider\"]\n3:I[69812,[\"177\",\"static/chunks/app/layout-cb2528e11420f193.js\"],\"ScreenSizeProvider\"]\n4:I[23449,[],\"\"]\n5:I[47869,[],\"\"]\n7:I[38310,[],\"OutletBoundary\"]\n9:I[38310,[],\"MetadataBoundary\"]\nb:I[38310,[],\"ViewportBoundary\"]\nd:I[95064,[],\"\"]\n:HL[\"/_next/static/media/34a9823ac715e2c2-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/4f05ba3a6752a328-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/88f55461e8246337-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/8f32c48a86b1398a-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/aa2fa0bf32820007-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/e0c8a07f5438bca2-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/d18faa20e57b8c8f.css\",\"style\"]\n:HL[\"/_next/static/css/8084700d1b690744.css\",\"style\"]\n:HL[\"/_next/static/css/a64b62f1bc63fa38.css\",\"style\"]\n:HL[\"/_next/static/css/7e01d6c3b6734420.css\",\"style\"]\n:HL[\"/_next/static/css/3051e00fa45cc288.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"YYD3mD2QdsFYN_w0NOAf7\",\"p\":\"\",\"c\":[\"\",\"projects\",\"2022\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[[\"project\",\"2022\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d18faa20e57b8c8f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/8084700d1b690744.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"className\":\"__variable_267f73 __variable_a17134\",\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_4bc053\",\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]}]}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"project\",\"2022\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L6\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/a64b62f1bc63fa38.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7e01d6c3b6734420.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/3051e00fa45cc288.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L7\",null,{\"children\":\"$L8\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"0d_fW6yAVeEX9JdpqDHC6\",{\"children\":[[\"$\",\"$L9\",null,{\"children\":\"$La\"}],[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Projects - Brainhack Western 2025\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Projects pitched at Brainhack Western\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"250x250\"}]]\n8:null\n"])</script><script>self.__next_f.push([1,"e:I[85471,[\"282\",\"static/chunks/282-afc53b6356b91afc.js\",\"45\",\"static/chunks/45-f916d720bcb3974c.js\",\"8\",\"static/chunks/8-b4524a3a6a8ca38b.js\",\"555\",\"static/chunks/app/projects/%5Bproject%5D/page-50d3f8ee355b2eaf.js\"],\"NavBar\"]\n10:I[2250,[\"282\",\"static/chunks/282-afc53b6356b91afc.js\",\"45\",\"static/chunks/45-f916d720bcb3974c.js\",\"8\",\"static/chunks/8-b4524a3a6a8ca38b.js\",\"555\",\"static/chunks/app/projects/%5Bproject%5D/page-50d3f8ee355b2eaf.js\"],\"default\"]\n12:I[19548,[\"282\",\"static/chunks/282-afc53b6356b91afc.js\",\"45\",\"static/chunks/45-f916d720bcb3974c.js\",\"8\",\"static/chunks/8-b4524a3a6a8ca38b.js\",\"555\",\"static/chunks/app/projects/%5Bproject%5D/page-50d3f8ee355b2eaf.js\"],\"\"]\n13:I[26036,[\"282\",\"static/chunks/282-afc53b6356b91afc.js\",\"45\",\"static/chunks/45-f916d720bcb3974c.js\",\"8\",\"static/chunks/8-b4524a3a6a8ca38b.js\",\"555\",\"static/chunks/app/projects/%5Bproject%5D/page-50d3f8ee355b2eaf.js\"],\"default\"]\n11:T410,Being confused, freezing, or panicking while trying hard to stop,\nre-direct, or stabilize a drone (or any such robot/toy) in sudden\ncounter-intuitive poses or environmental conditions is likely a\nrelatable experience for all of us. The idea here is about enhancing the\nexpression of our intent while controlling a robot remotely ‚Äî either in\nreal life or on a computer screen (simulation) ‚Äî while not replacing the\nprimary instrument of control (modality) but instead by also integrating\nour brain states (thought) in the control loop as measured, for example,\nthrough EEG. Specifically, for the scope of the hackathon, this could\nmean developing a brain-machine interface for automatically assisting\nthe operator in emergency cases with ‚Äúsmart‚Äù control command reflexes or\n‚Äútakeovers‚Äù. Such an approach can be beneficial in high-risk cases such\nas remote handling of materials in nuclear facilities or it can also aid\nthe supervision of autonomous control, say in the context of\nself-driving cars, to ultimately increase safety."])</script><script>self.__next_f.push([1,"6:[\"$\",\"div\",null,{\"className\":\"_1n606ht0\",\"children\":[[\"$\",\"$Le\",null,{\"displaySections\":{\"tutorial\":false,\"schedule\":false,\"twitterFeed\":false},\"splashMode\":false,\"registrationButton\":null,\"projectUrl\":\"/projects/2023\"}],[\"$\",\"article\",null,{\"ref\":\"$undefined\",\"style\":\"$undefined\",\"children\":[[\"$\",\"h1\",null,{\"children\":\"Projects\"}],[\"$\",\"div\",null,{\"className\":\"_1k0mdyo0\",\"children\":[\"$\",\"div\",null,{\"className\":\"_1k0mdyo1\",\"children\":[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"children\":[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"Project Submission for Brainhack Western \",2025,\" will open soon!\",[\"$\",\"br\",null,{}],\"In the meantime, check out the project pitches from previous years.\"],\"ref\":\"$undefined\",\"className\":\"d-flex flex-column align-items-center justify-content-center col-lg-6\"}],[\"$\",\"div\",null,{\"children\":\"$Lf\",\"ref\":\"$undefined\",\"className\":\"col-lg-6\"}]],\"className\":\"row\"}],\"className\":\"container-lg\"}]}]}],[\"$\",\"$L10\",null,{\"years\":[\"2021\",\"2022\",\"2023\"],\"def\":\"2022\"}],null,[[\"$\",\"section\",\"Safer-Multimodal-Teleoperation-of-Simulated-Robots\",{\"id\":\"Safer-Multimodal-Teleoperation-of-Simulated-Robots\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"Safer Multimodal Teleoperation of (Simulated) Robots\"}],[\"$\",\"div\",null,{\"className\":\"console \",\"children\":[\"$\",\"span\",null,{\"children\":[[[\"$\",\"p\",\"p-0\",{\"children\":\"$11\"}],\"\\n\",[\"$\",\"p\",\"p-1\",{\"children\":\"For now, we could pick a particular type of simulated robot (industrial\\narms, RC cars, drones, etc.) and focus on designing and implementing a\\nparadigm for characterizing intended motion and surprise during\\nundesired motion in both autonomous (with no user control but robot's\\nself- and environmental influences) or semi-autonomous cases (including\\nuser's control commands), i.e., we can aim to measure intent and\\nsurprise given the user's control commands, the brain states, and robot\\nstates during algorithmically curated cases of robot motion. This will\\nhelp us detect such situations and also infer desired reactions to\\naccordingly adjust control commands to achieve desired reactions during\\nemergencies and, more generally, to augment real-time active control to\\nmatch the desired motion. We can strive to keep the approach suitable\\nfor generalizing well enough to robots of other types and/or\\nmorphologies and to more unusual environments.\"}]],null,[\"$\",\"div\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"green\",\"children\":\"Organizer: \"}],[\"$\",\"br\",null,{}],[[\"$\",\"div\",\"Pranshu Malik\",{\"className\":\"d-flex\",\"children\":[[\"$\",\"span\",null,{\"children\":\"¬†¬†-¬†\"}],[\"$\",\"div\",null,{\"children\":[\"Pranshu Malik\",[\" \",\"(\",[\"$\",\"$L12\",null,{\"href\":\"https://github.com/pranshumalik14\",\"children\":[\"@\",\"pranshumalik14\"]}],\")\"]]}],[\"$\",\"br\",null,{}]]}]]]}]]}]}]]}],[\"$\",\"section\",\"Brain3DVis-AR/MR-MRI-Visualizer\",{\"id\":\"Brain3DVis-AR/MR-MRI-Visualizer\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"Brain3DVis: AR/MR MRI Visualizer\"}],[\"$\",\"div\",null,{\"className\":\"console \",\"children\":[\"$\",\"span\",null,{\"children\":[[[\"$\",\"p\",\"p-0\",{\"children\":[\"Application that uses a web-based front end where users can submit brain\\nMRI volumes. The data is then processed on the application backend, a 3D\\nmodel is generated, and is then accessible in a AR/VR environment. We\\nare using the MERN stack for the web component and C#/Unity for the\\nAR/VR application. We would love to work with people who have experience\\nwith MRI volumetric segmentation or are interested in VR/AR data\\nvisualization. \",[\"$\",\"span\",\"span-0\",{\"role\":\"img\",\"aria-label\":\"slightly smiling face emoji\",\"children\":\"üôÇ\"}]]}]],null,[\"$\",\"div\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"green\",\"children\":\"Organizer: \"}],[\"$\",\"br\",null,{}],[[\"$\",\"div\",\"Liam Bilbie\",{\"className\":\"d-flex\",\"children\":[[\"$\",\"span\",null,{\"children\":\"¬†¬†-¬†\"}],[\"$\",\"div\",null,{\"children\":[\"Liam Bilbie\",[\" \",\"(\",[\"$\",\"$L12\",null,{\"href\":\"https://github.com/LiamBilbie\",\"children\":[\"@\",\"LiamBilbie\"]}],\")\"]]}],[\"$\",\"br\",null,{}]]}]]]}]]}]}]]}],[\"$\",\"section\",\"Functional-Atlas-Explorer\",{\"id\":\"Functional-Atlas-Explorer\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"Functional Atlas Explorer\"}],[\"$\",\"div\",null,{\"className\":\"console \",\"children\":[\"$\",\"span\",null,{\"children\":[[[\"$\",\"p\",\"p-0\",{\"children\":\"\\\"What does the inferior frontal gyrus do?\\\" Googling this question\\nreturns 93,400,000 results. A skim read of paper abstracts will give you\\nsome ideas about its functions. But wouldn't it be useful to have an\\ninteractive map where you can explore these functions in the brain?\\nImagine clicking on a brain region and getting a word cloud of functions\\nthat this region is highly involved in. That's what we will build!\"}],\"\\n\",[\"$\",\"p\",\"p-1\",{\"children\":\"We will create an interactive tool, useful for anyone wanting to explore\\ntheir own functional data or openly available functional datasets.\\nTogether with our functional fusion toolbox (in-house \u0026 soon to be\\nreleased), it lets you integrate information from many different openly\\navailable datasets (Human Connectome Project, etc).\"}],\"\\n\",[\"$\",\"p\",\"p-2\",{\"children\":\"During the project you will be able to use our existing toolbox to\\nexplore these large datasets - as well as your own data! In addition,\\nthis interactive map will provide a side by side view of your desired\\nbrain regions and their connections with other brain regions. Click on a\\nregion and you get a map of its functional connectivity to all other\\nregions in the brain.\"}],\"\\n\",[\"$\",\"p\",\"p-3\",{\"children\":\"The tool will help synthesize findings across studies (think Neurosynth,\\nbut directly based on fMRI data) and aid interpretation of results as\\nwell as planning of future experiments.\"}]],null,[\"$\",\"div\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"green\",\"children\":\"Organizers: \"}],[\"$\",\"br\",null,{}],[[\"$\",\"div\",\"Caroline Nettekoven\",{\"className\":\"d-flex\",\"children\":[[\"$\",\"span\",null,{\"children\":\"¬†¬†-¬†\"}],[\"$\",\"div\",null,{\"children\":[\"Caroline Nettekoven\",[\" \",\"(\",[\"$\",\"$L12\",null,{\"href\":\"https://github.com/carobellum\",\"children\":[\"@\",\"carobellum\"]}],\")\"]]}],[\"$\",\"br\",null,{}]]}],[\"$\",\"div\",\"Ladan Shahshahani\",{\"className\":\"d-flex\",\"children\":[[\"$\",\"span\",null,{\"children\":\"¬†¬†-¬†\"}],[\"$\",\"div\",null,{\"children\":[\"Ladan Shahshahani\",[\" \",\"(\",[\"$\",\"$L12\",null,{\"href\":\"https://github.com/lshahsha\",\"children\":[\"@\",\"lshahsha\"]}],\")\"]]}],[\"$\",\"br\",null,{}]]}]]]}]]}]}]]}],[\"$\",\"section\",\"DWI-Fiducials\",{\"id\":\"DWI-Fiducials\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"DWI Fiducials\"}],[\"$\",\"div\",null,{\"className\":\"console \",\"children\":[\"$\",\"span\",null,{\"children\":[[[\"$\",\"p\",\"p-0\",{\"children\":\"Diffusion-Weighted Imaging (DWI) is a variant of the standard MRI\\nsequence examining the diffusion rate of water molecules.  DWI or\\nDiffusion MRI has allowed for the improved study of white matter\\npathways across both diseased and healthy patients.\"}],\"\\n\",[\"$\",\"p\",\"p-1\",{\"children\":[\"The goal of the diffusion Fiducials or dFIDs project is to identify a\\nset of anatomical landmarks on a variety of Diffusion-Weighted MRI\\nimages that are both salient and have functional significance.  This\\nwill be an extension of the previous Anatomical Fiducials (AFIDs)\\nproject that has localized a set of 32 clinically-relevant landmarks in\\nhumans, macaques, and PD patients in multiple imaging acquisitions (see\\n\",[\"$\",\"a\",\"a-0\",{\"href\":\"https://doi.org/10.1002/hbm.24693\",\"children\":\"https://doi.org/10.1002/hbm.24693\"}],\").\"]}],\"\\n\",[\"$\",\"p\",\"p-2\",{\"children\":\"We are looking for students, researchers, and clinicians to determine\\npotential fiducials across various acquisition types and models in DWI.\\nThose with experience in acquiring diffusion images or who have an\\ninterest in neuroimaging or anatomy are welcome to join!\"}]],null,[\"$\",\"div\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"green\",\"children\":\"Organizer: \"}],[\"$\",\"br\",null,{}],[[\"$\",\"div\",\"Arun Thurairajah\",{\"className\":\"d-flex\",\"children\":[[\"$\",\"span\",null,{\"children\":\"¬†¬†-¬†\"}],[\"$\",\"div\",null,{\"children\":[\"Arun Thurairajah\",null]}],[\"$\",\"br\",null,{}]]}]]]}]]}]}]]}]]],\"className\":\"_1p0a9t10 container-lg\"}],[\"$\",\"footer\",null,{\"className\":\"_1d8l4x30\",\"children\":[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"id\":\"$undefined\",\"children\":[[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"children\":[[\"$\",\"div\",null,{\"className\":\"col-lg-6 d-flex flex-column justify-content-start align-items-start\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"Organizers\"}],[\"$\",\"p\",null,{\"className\":\"organizers\",\"children\":\"Ali Tafakkor, Peter Van Dyken, Ali Khan\"}]]}],null],\"className\":\"row\"}],[\"$\",\"h3\",null,{\"id\":\"contact\",\"children\":\"Contact\"}],[\"$\",\"$L13\",null,{\"email\":\"brainhack.western@gmail.com\"}],[\"$\",\"p\",null,{\"className\":\"_1d8l4x31\",\"children\":[\"Copyright ¬© \",2025,\" Brainhack Western\"]}]],\"className\":\"_1d1a9if0  container-lg\"}]}]]}]\n"])</script><script>self.__next_f.push([1,"f:[\"$\",\"div\",null,{\"className\":\"align-self-lg-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"console \",\"children\":[\"$\",\"span\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"blue\",\"children\":\"# Coming soon\"}],[\"$\",\"br\",null,{}],[\"$\",\"span\",null,{\"children\":\"Mar 19 - Mar 21\"}],null]}]}]}]\n"])</script></body></html>